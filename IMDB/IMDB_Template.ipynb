{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### IMDB 分类模板"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 引入pytorch包\n",
    "import torch\n",
    "\n",
    "from torch import nn, optim\n",
    "from torch.nn import init\n",
    "\n",
    "import torchtext\n",
    "from torchtext.vocab import Vectors\n",
    "from torchtext import data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 引入其他包\n",
    "from tqdm import tqdm\n",
    "import time\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 随机数层\n",
    "SEED = 12345\n",
    "\n",
    "torch.manual_seed(SEED)\n",
    "torch.cuda.manual_seed(SEED)\n",
    "torch.backends.cudnn.deterministic = True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 常数、参数层，常数及可变参数用大写字母表示\n",
    "\n",
    "DEVICE = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 数据层，设置IMDBDataset和IMDBDataLoader，并打印一些数据，确保Dataset没问题\n",
    "\n",
    "SENTENCE = data.Field(sequential=True, lower=True, include_lengths=True, use_vocab=True, batch_first=False)\n",
    "LABEL = data.LabelField(sequential=False, use_vocab=True)\n",
    "\n",
    "trainDataset, valDataset = data.TabularDataset.splits(path='.', train='IMDBTrain.tsv', validation='IMDBTest.tsv', format='tsv', skip_header=True, fields=[('sentence', SENTENCE), ('label', LABEL)])\n",
    "\n",
    "vectors = torchtext.vocab.Vectors(name = 'glove.6B.100d.txt', cache = '../../glove')\n",
    "SENTENCE.build_vocab(trainDataset, vectors=vectors, unk_init=init.xavier_normal)\n",
    "LABEL.build_vocab(trainDataset)\n",
    "\n",
    "print(\"SENTENCE.vocab.freqs.most_common(10)\\n\", SENTENCE.vocab.freqs.most_common(10))\n",
    "print(\"SENTENCE.vocab.vectors.shape\\n\", SENTENCE.vocab.vectors.shape)\n",
    "\n",
    "\n",
    "trainIter = data.BucketIterator(trainDataset, batch_size=16, sort_key=lambda x: len(x.sentence), shuffle=True, device=DEVICE)\n",
    "valIter = data.BucketIterator(valDataset, batch_size=32, sort_key=lambda x: len(x.sentence), shuffle=True, device=DEVICE)\n",
    "# # 迭代器返回一个名为torchtext.data.Batch的自定义数据类型，使得代码重用变得困难，使得torchtext很难与其他库一起用于某些用例。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'nn' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-1-c4a82bac0946>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;31m# 模型层，在这里定义模型\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 3\u001b[0;31m \u001b[0;32mclass\u001b[0m \u001b[0mIMDBModel\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnn\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mModule\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      4\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m__init__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m         \u001b[0;32mpass\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'nn' is not defined"
     ]
    }
   ],
   "source": [
    "# 模型层，在这里定义模型\n",
    "\n",
    "class IMDBModel(nn.Module):\n",
    "    def __init__(self):\n",
    "        pass\n",
    "    \n",
    "    def forward(self, inputs):\n",
    "        pass\n",
    "    \n",
    "imdbModel = IMDBModel()\n",
    "imdbModel = imdbModel.to(DEVICE)\n",
    "\n",
    "# 对模型加入参数，如embedding等数据"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "INPUT_DIM = len(SENTENCE.vocab)\n",
    "EMBEDDING_DIM = 100\n",
    "HIDDEN_DIM = 50\n",
    "OUTPUT_DIM = 2\n",
    "N_LAYERS = 2\n",
    "BIDIRECTIONAL = True\n",
    "DROPOUT = 0.2\n",
    "PAD_IDX = SENTENCE.vocab.stoi[SENTENCE.pad_token]\n",
    "\n",
    "model = RNN2(INPUT_DIM, EMBEDDING_DIM, HIDDEN_DIM, OUTPUT_DIM, \n",
    "            N_LAYERS, BIDIRECTIONAL, DROPOUT, PAD_IDX)\n",
    "model = model.to(DEVICE)\n",
    "\n",
    "pretrained_embeddings = SENTENCE.vocab.vectors\n",
    "\n",
    "model.embedding.weight.data.copy_(pretrained_embeddings)\n",
    "UNK_IDX = SENTENCE.vocab.stoi[SENTENCE.unk_token]\n",
    "\n",
    "model.embedding.weight.data[UNK_IDX] = torch.zeros(EMBEDDING_DIM)\n",
    "model.embedding.weight.data[PAD_IDX] = torch.zeros(EMBEDDING_DIM)\n",
    "\n",
    "print(model.embedding.weight.data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 优化层，设置损失函数，优化器\n",
    "\n",
    "optimizer = optim.Adam(imdbModel.parameter())\n",
    "\n",
    "criterion = nn.CrossEntropyLoss()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 辅助函数层，如训练函数、验证函数、运行时间函数\n",
    "def train(model, iterator, optimizer, criterion, skip=500):\n",
    "    \n",
    "    epoch_loss = 0\n",
    "    epoch_acc = 0\n",
    "    model.train()\n",
    "    \n",
    "    for i, batch in enumerate(iterator):\n",
    "        optimizer.zero_grad()\n",
    "        predictions = model(batch.sentence[0], batch.sentence[1])\n",
    "        #print(\"predictions \", predictions.size())\n",
    "        loss = criterion(predictions, batch.label)\n",
    "        \n",
    "\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        \n",
    "        _, preds = torch.max(predictions.detach(), dim=1)\n",
    "        acc = torch.mean((preds==batch.label.detach()).double())\n",
    "\n",
    "        epoch_loss += loss.item()\n",
    "        \n",
    "        \n",
    "        \n",
    "        epoch_acc += acc.item()\n",
    "        if i % skip == 0:\n",
    "            print(\" Train Mini batch loss \", loss.item())\n",
    "            print(\" Train Mini batch acc  \", acc.item())\n",
    "    return epoch_loss / len(iterator), epoch_acc / len(iterator)\n",
    "\n",
    "def evaluate(model, iterator, criterion, skip=500):\n",
    "    \n",
    "    epoch_loss = 0\n",
    "    epoch_acc = 0\n",
    "    model.eval()\n",
    "    \n",
    "    with torch.no_grad():\n",
    "        for i, batch in enumerate(iterator):\n",
    "            predictions = model(batch.sentence[0], batch.sentence[1])\n",
    "            loss = criterion(predictions, batch.label)\n",
    "\n",
    "            epoch_loss += loss.item()\n",
    "            _, preds = torch.max(predictions, dim=1)\n",
    "            acc = torch.mean((preds==batch.label).double())\n",
    "            \n",
    "            epoch_acc += acc.item()\n",
    "            if i % skip == 0:\n",
    "                print(\"Valid Mini batch loss \", loss.item())\n",
    "                print(\"Valid Mini batch acc  \", acc.item())\n",
    "    return epoch_loss / len(iterator), epoch_acc / len(iterator)\n",
    "\n",
    "\n",
    "def epoch_time(start_time, end_time):\n",
    "    elapsed_time = end_time - start_time\n",
    "    elapsed_mins = int(elapsed_time / 60)\n",
    "    elapsed_secs = int(elapsed_time - (elapsed_mins * 60))\n",
    "    return elapsed_mins, elapsed_secs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 执行层，设置训练过程，验证过程，在这里执行优化，并记录效果最佳的模型，打开tensorboard，记录执行时的各个参数\n",
    "N_EPOCHS = 10\n",
    "best_valid_acc = float('0.0')\n",
    "\n",
    "import copy\n",
    "best_model_state_dict = copy.deepcopy(model.state_dict())\n",
    "best_epoch = 0\n",
    "\n",
    "for epoch in range(N_EPOCHS):\n",
    "\n",
    "    start_time = time.time()\n",
    "    \n",
    "    \n",
    "    train_loss, train_acc = train(model, trainIter, optimizer, criterion)\n",
    "    valid_loss, valid_acc = evaluate(model, valIter, criterion)\n",
    "    end_time = time.time()\n",
    "\n",
    "    epoch_mins, epoch_secs = epoch_time(start_time, end_time)\n",
    "    \n",
    "    if valid_acc > best_valid_acc:\n",
    "        best_model_state_dict = copy.deepcopy(model.state_dict())\n",
    "        best_epoch = epoch\n",
    "        best_valid_acc = best_valid_acc\n",
    "    \n",
    "    print(f'Epoch: {epoch+1:2} | Epoch Time: {epoch_mins}m {epoch_secs}s')\n",
    "    print(f'\\n\\tTrain Loss: {train_loss:.3f} ')\n",
    "    print(f'\\tValid Loss: {valid_loss:.3f} \\tValid Acc: {valid_acc:.3f} \\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 记录层，记录一系列数据\n",
    "xxx模型\n",
    "参数：\n",
    "optim  lr  max_length   final_acc\n",
    "SGD   1e-3  128         \n",
    "\n",
    "效果：验证集最佳为91%"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "# 反馈层，打印一些效果不好的数据，通过人工思考，为什么模型对这些效果不好的数据没效果。\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
