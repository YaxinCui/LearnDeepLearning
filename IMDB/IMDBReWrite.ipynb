{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch import nn, optim\n",
    "from torch.utils.data import DataLoader\n",
    "import torch\n",
    "\n",
    "from torch.nn.utils.rnn import pack_padded_sequence, pad_packed_sequence\n",
    "\n",
    "import numpy as np\n",
    "\n",
    "from tqdm import tqdm\n",
    "\n",
    "from IMDBDataset import IMDBDataset\n",
    "from IMDBTokenizers import IMDBTokenizer\n",
    "from IMDBmodels import IMDBLstm\n",
    "\n",
    "# dataLoader\n",
    "# tokenizer\n",
    "# Model\n",
    "# train\n",
    "# showLossAndError\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 常量层\n",
    "torch.manual_seed(1)\n",
    "\n",
    "\n",
    "word_dim=100\n",
    "device = torch.device('cuda:0' if torch.cuda.is_available() else \"cpu\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "400001it [00:10, 36618.47it/s]\n",
      "100%|██████████| 62596/62596 [00:00<00:00, 389919.23it/s]\n"
     ]
    }
   ],
   "source": [
    "imdbTokenizer = IMDBTokenizer(vocab_path='aclImdb/imdb.vocab', glove_path='../../glove.6B.100d.txt', word_dim=word_dim, special_tokens=['<PAD>', '<UNK>'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "共有pos数据 12500 条, neg数据 12500 条，共 25000 条\n",
      "共有pos数据 12500 条, neg数据 12500 条，共 25000 条\n"
     ]
    }
   ],
   "source": [
    "trainIMDBDataset = IMDBDataset('./aclImdb/train')\n",
    "trainIMDBDataLoader = DataLoader(trainIMDBDataset, batch_size=16, shuffle=True)\n",
    "trainSmallIMDBDataLoader = DataLoader(trainIMDBDataset, batch_size=1, shuffle=True)\n",
    "\n",
    "testIMDBDataset = IMDBDataset('./aclImdb/test')\n",
    "testIMDBDataLoader = DataLoader(testIMDBDataset, batch_size=8, shuffle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "imdbLSTM = IMDBLstm(imdbTokenizer, 100, word_dim, 256, 2, True, num_labels=2, device=device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "imdbLSTM = imdbLSTM.to(device)\n",
    "\n",
    "# 查看模型的各个层，设置初始化策略，设置参数\n",
    "base_lr = 0.1\n",
    "\n",
    "embedding_parameters = list(map(id, imdbLSTM.embedding.parameters()))\n",
    "\n",
    "base_params = filter(lambda p: id(p) not in embedding_parameters, imdbLSTM.parameters())\n",
    "\n",
    "optimizer = optim.Adam([{'params': base_params}, \n",
    "                        {'params': imdbLSTM.embedding.parameters(), 'lr': base_lr * 0.1}], lr=base_lr,betas=(0.9,0.999))\n",
    "\n",
    "\n",
    "criterion = nn.NLLLoss()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 0/10\n",
      "Mini epoch: 0/1563 loss 0.6902734041213989, acc 9/16=0.5625\n",
      "Mini epoch: 100/1563 loss 2.6618688106536865, acc 9/16=0.5625\n",
      "Mini epoch: 200/1563 loss 1.402869462966919, acc 10/16=0.625\n",
      "Mini epoch: 300/1563 loss 2.0885932445526123, acc 11/16=0.6875\n",
      "Mini epoch: 400/1563 loss 6.414031505584717, acc 8/16=0.5\n",
      "Mini epoch: 500/1563 loss 1.8173062801361084, acc 7/16=0.4375\n",
      "Mini epoch: 600/1563 loss 0.8748462200164795, acc 6/16=0.375\n",
      "Mini epoch: 700/1563 loss 0.7348121404647827, acc 7/16=0.4375\n",
      "Mini epoch: 800/1563 loss 1.4061627388000488, acc 4/16=0.25\n",
      "Mini epoch: 900/1563 loss 3.287309169769287, acc 9/16=0.5625\n",
      "Mini epoch: 1000/1563 loss 0.6530912518501282, acc 11/16=0.6875\n",
      "Mini epoch: 1100/1563 loss 2.831125497817993, acc 4/16=0.25\n",
      "Mini epoch: 1200/1563 loss 0.8249785900115967, acc 9/16=0.5625\n",
      "Mini epoch: 1300/1563 loss 2.341109275817871, acc 10/16=0.625\n",
      "Mini epoch: 1400/1563 loss 0.9394770264625549, acc 8/16=0.5\n",
      "Mini epoch: 1500/1563 loss 0.7378884553909302, acc 10/16=0.625\n",
      "Epoch: 0/10 loss:2.2961692742347717, acc 12584/25000=0.50336\n",
      "epoch 1/10\n",
      "Mini epoch: 0/1563 loss 0.9386019110679626, acc 9/16=0.5625\n"
     ]
    }
   ],
   "source": [
    "epochs = 10\n",
    "skip = 100\n",
    "import copy\n",
    "model = imdbLSTM\n",
    "\n",
    "for epoch in range(epochs):\n",
    "    model = model.to(device)\n",
    "    print(\"epoch {}/{}\".format(epoch, epochs))\n",
    "    \n",
    "    epoch_total_loss = 0.0\n",
    "    epoch_acc_num = 0\n",
    "    epoch_total_num = 0\n",
    "    \n",
    "    best_model = copy.deepcopy(model.state_dict())\n",
    "    best_model_acc = 0.0\n",
    "    \n",
    "    for i, (inputs, labels) in enumerate(trainIMDBDataLoader):\n",
    "        labels = labels.to(device)\n",
    "        \n",
    "        inputs = [str(i) for i in inputs]\n",
    "        imdbLSTM.train()\n",
    "        optimizer.zero_grad()\n",
    "        outputs = imdbLSTM(inputs)\n",
    "        loss = criterion(outputs, labels)\n",
    "        \n",
    "        nn.utils.clip_grad_norm_(model.parameters(), max_norm=20, norm_type=2)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "        _, preds = torch.max(outputs, 1)\n",
    "        acc_num = torch.sum(preds==labels)\n",
    "        \n",
    "        epoch_total_loss += loss.item() * len(outputs)\n",
    "        epoch_total_num += len(outputs)\n",
    "        epoch_acc_num += acc_num\n",
    "                    \n",
    "        \n",
    "        if i % skip == 0:\n",
    "            print('Mini epoch: {}/{} loss {}, acc {}/{}={}'.format(i, len(trainIMDBDataLoader), loss.item(), acc_num, len(labels), acc_num.double()/len(labels)))\n",
    "        else:\n",
    "            \n",
    "    epoch_acc = epoch_acc_num.double()/epoch_total_num\n",
    "    print('Epoch: {}/{} loss:{}, acc {}/{}={}'.format(epoch, epochs, epoch_total_loss/epoch_total_num, epoch_acc_num, epoch_total_num, epoch_acc))\n",
    "    \n",
    "    if epoch_acc > best_model_acc:\n",
    "        best_model = copy.deepcopy(model.state_dict())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
